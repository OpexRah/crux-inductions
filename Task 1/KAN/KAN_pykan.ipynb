{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Documents\\\\GitHub\\\\crux-inductions\\\\Task 1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset and prepare it for KAN model\n",
    "\n",
    "df = pd.read_csv(\"Dataset/iris.csv\")\n",
    "df[\"variety\"].replace([\"Setosa\", \"Versicolor\", \"Virginica\"], [0., 1., 2.], inplace=True) #replace the categorical labels with numbers\n",
    "df = df.sample(frac=1, random_state=0).reset_index(drop=True) #shuffle the dataset\n",
    "\n",
    "X = np.array(df.iloc[:, :-1].values)\n",
    "Y = np.array(df.iloc[:, -1].values)\n",
    "X = torch.from_numpy(X).float() # KAN needs its data in torch.tensor dtype\n",
    "Y = torch.from_numpy(Y).type(torch.LongTensor) # CrossEntropyLoss needs the labels to be in integer dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.85\n",
    "\n",
    "X_train = X[:int(len(X)*train_split)]\n",
    "Y_train = Y[:int(len(Y)*train_split)]\n",
    "X_test = X[int(len(X)*train_split):]\n",
    "Y_test = Y[int(len(Y)*train_split):]\n",
    "\n",
    "dataset = {}\n",
    "dataset[\"train_input\"] = X_train\n",
    "dataset[\"test_input\"] = X_test\n",
    "dataset[\"train_label\"] = Y_train\n",
    "dataset[\"test_label\"] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KAN model with 3 hidden layers of width 4, 5, and 3 respectively, grid size of 3, and k=3\n",
    "\"\"\"\n",
    "model = KAN(width=[4,5,3], grid=3, k=3, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/20 [00:00<?, ?it/s]c:\\Users\\trail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "train loss: 2.27e-04 | test loss: 5.52e+00 | reg: 4.91e+02 : 100%|██| 20/20 [00:12<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "define training and testing accuracy functions which will be used as metrics for KAN.train() method\n",
    "\"\"\"\n",
    "\n",
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['train_input']), dim=1) == dataset['train_label']).float())\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).float())\n",
    "\n",
    "# train the model\n",
    "results = model.train(dataset, opt=\"LBFGS\", steps=20, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9130434989929199\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "print(f\"Train Accuracy: {results['train_acc'][-1]}\")\n",
    "print(f\"Test Accuracy: {results['test_acc'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing (0,0,0) with log, r2=0.9991572499275208\n",
      "fixing (0,0,1) with x^3, r2=0.8089573979377747\n",
      "fixing (0,0,2) with sin, r2=0.998892068862915\n",
      "fixing (0,0,3) with sin, r2=0.9976062178611755\n",
      "fixing (0,0,4) with sin, r2=0.9994670748710632\n",
      "fixing (0,1,0) with sin, r2=0.9999797344207764\n",
      "fixing (0,1,1) with sin, r2=1.0000001192092896\n",
      "fixing (0,1,2) with sin, r2=0.9999666810035706\n",
      "fixing (0,1,3) with exp, r2=0.9998781681060791\n",
      "fixing (0,1,4) with sin, r2=0.9995633363723755\n",
      "fixing (0,2,0) with sin, r2=0.9999454021453857\n",
      "fixing (0,2,1) with sin, r2=0.9999930262565613\n",
      "fixing (0,2,2) with sqrt, r2=0.9999890923500061\n",
      "fixing (0,2,3) with sin, r2=0.999992311000824\n",
      "fixing (0,2,4) with x^2, r2=0.9999874830245972\n",
      "fixing (0,3,0) with tanh, r2=0.9998378753662109\n",
      "fixing (0,3,1) with sin, r2=0.9999805092811584\n",
      "fixing (0,3,2) with tanh, r2=0.9999189972877502\n",
      "fixing (0,3,3) with tanh, r2=0.9999874234199524\n",
      "fixing (0,3,4) with sin, r2=0.9999833106994629\n",
      "fixing (1,0,0) with x^2, r2=0.9976719617843628\n",
      "fixing (1,0,1) with x^2, r2=0.9904473423957825\n",
      "fixing (1,0,2) with exp, r2=0.9992626905441284\n",
      "fixing (1,1,0) with abs, r2=0.9999972581863403\n",
      "fixing (1,1,1) with abs, r2=1.0000001192092896\n",
      "fixing (1,1,2) with abs, r2=0.9999991059303284\n",
      "fixing (1,2,0) with abs, r2=0.9999995231628418\n",
      "fixing (1,2,1) with abs, r2=0.9999988675117493\n",
      "fixing (1,2,2) with exp, r2=0.9999970197677612\n",
      "fixing (1,3,0) with abs, r2=0.9973635077476501\n",
      "fixing (1,3,1) with x^4, r2=0.8995717167854309\n",
      "fixing (1,3,2) with sin, r2=0.9964421391487122\n",
      "fixing (1,4,0) with abs, r2=0.999902606010437\n",
      "fixing (1,4,1) with abs, r2=0.9999111890792847\n",
      "fixing (1,4,2) with exp, r2=0.9953965544700623\n",
      "Formula 1 :281709.35*(-0.01*log(2.54*x_1 - 6.63) - 0.e-2*sin(0.53*x_2 - 8.22) - sin(0.01*x_3 + 8.8) + 0.01*tanh(1.51*x_4 - 1.74) + 0.58)**2 - 14.8*Abs(682.83*(1 - 0.03*x_3)**2 + 1.64*sin(1.24*x_1 - 4.4) + 8.97*sin(1.73*x_2 + 6.8) + 45.74*sin(1.2*x_4 + 7.8) - 666.82) + 1.25*Abs(20357.4*(0.16*x_1 - 1)**3 - 2822.31*sin(0.18*x_2 - 3.54) - 2316.02*sin(0.16*x_3 - 6.8) + 568.62*sin(1.2*x_4 + 7.59) + 2604.66) - 6.18*Abs(20157.8*sqrt(0.04*x_3 + 1) + 165.78*sin(1.22*x_1 - 1.49) - 394.69*sin(0.44*x_2 + 5.84) + 989.38*tanh(1.0*x_4 - 1.82) - 19116.74) + 3.65*Abs(9.54*sin(1.62*x_1 + 5.08) - 169.59*sin(0.16*x_3 - 6.8) + 64.66*tanh(0.88*x_4 - 1.76) + 177.53 - 225.8*exp(-0.08*x_2)) + 135.9\n",
      "\n",
      "Formula 2:-2129451.81*(-0.01*log(2.54*x_1 - 6.63) - 0.e-2*sin(0.53*x_2 - 8.22) - sin(0.01*x_3 + 8.8) + 0.01*tanh(1.51*x_4 - 1.74) + 0.58)**2 - 47111.25*(0.04*sin(1.62*x_1 + 5.08) - 0.75*sin(0.16*x_3 - 6.8) + 0.29*tanh(0.88*x_4 - 1.76) + 0.93 - exp(-0.08*x_2))**4 + 15.91*Abs(562.52*(1 - 0.03*x_3)**2 + 1.35*sin(1.24*x_1 - 4.4) + 7.39*sin(1.73*x_2 + 6.8) + 37.68*sin(1.2*x_4 + 7.8) - 549.64) + 0.5*Abs(15064.48*(0.16*x_1 - 1)**3 - 2088.51*sin(0.18*x_2 - 3.54) - 1713.86*sin(0.16*x_3 - 6.8) + 420.78*sin(1.2*x_4 + 7.59) + 1930.3) + 1.6*Abs(23439.31*sqrt(0.04*x_3 + 1) + 192.77*sin(1.22*x_1 - 1.49) - 458.94*sin(0.44*x_2 + 5.84) + 1150.44*tanh(1.0*x_4 - 1.82) - 22230.39) - 224.5\n",
      "\n",
      "Formula 3:1.96*(0.38*x_1 - 1)**0.16*exp(0.09*sin(0.53*x_2 - 8.22) + 13.33*sin(0.01*x_3 + 8.8) - 0.07*tanh(1.51*x_4 - 1.74)) - 583566.58*exp(-0.19*sqrt(0.04*x_3 + 1) - 0.e-2*tanh(1.0*x_4 - 1.82)) - 181.17*exp(2.09*(1 - 0.03*x_3)**2 + 0.01*sin(1.24*x_1 - 4.4) + 0.03*sin(1.73*x_2 + 6.8) + 0.14*sin(1.2*x_4 + 7.8)) + 88.22*sin(0.37*sin(1.62*x_1 + 5.08) - 6.64*sin(0.16*x_3 - 6.8) + 2.53*tanh(0.88*x_4 - 1.76) + 13.9 - 8.84*exp(-0.08*x_2)) - 1.7*Abs(17572.51*(0.16*x_1 - 1)**3 - 2436.21*sin(0.18*x_2 - 3.54) - 1999.19*sin(0.16*x_3 - 6.8) + 490.83*sin(1.2*x_4 + 7.59) + 2250.01) + 486143.9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pykan also allows us to see the symbolic formula of the model. In this case we have 3 formulas each corresponding to a class.\n",
    "Each formula has 4 variables which correspond to our 4 features in the iris dataset. Plugging in the values of these variables will \n",
    "give us the probability of the input belonging to that class.\n",
    "\n",
    "Note that the formulas generated are not the same as the ones used to generate the data. (ideal function) \n",
    "They are just and approximation of the function that the model has learned and is true upto some error threshold given by \n",
    "the Kolmogorov-Arnold representation theorem.\n",
    "\"\"\"\n",
    "\n",
    "symbols = ['x','x^2','x^3','x^4','exp','log','sqrt','tanh','sin','abs'] #symbols that can be used in the formula\n",
    "model.auto_symbolic(lib=symbols) #generate the symbolic formula\n",
    "\n",
    "\n",
    "formula1, formula2, formula3 = model.symbolic_formula()[0]\n",
    "print(f\"Formula 1 :{formula1}\\n\\nFormula 2:{formula2}\\n\\nFormula 3:{formula3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
